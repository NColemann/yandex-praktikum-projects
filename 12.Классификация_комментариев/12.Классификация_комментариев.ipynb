{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "\n",
    "**Этапы выполнения проекта:**\n",
    "\n",
    "1. Загрузка и подготовка данных.\n",
    "2. Обучение разных моделей. \n",
    "3. Выводы.\n",
    "\n",
    "\n",
    "Столбец *text* содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pymystem3 import Mystem\n",
    "from catboost import CatBoostClassifier, Pool, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Деление на обучающую и тестовую выборки\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    comments['text'], comments['toxic'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим корпус комментариев и преобразуем кодировку текста в unicode\n",
    "corpus_train = train_features.values.astype('U')\n",
    "corpus_test = test_features.values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лемматизация текста\n",
    "def lemmatize(text):\n",
    "    lemm = m.lemmatize(text)  \n",
    "    return \"\".join(lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d097375bbb74ce1bf0debac2b534882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119678.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in notebook.tqdm(range(corpus_train.shape[0])):\n",
    "    corpus_train[i] = lemmatize(corpus_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7585194c8fff45a7b348fb836434e3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39893.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in notebook.tqdm(range(corpus_test.shape[0])):\n",
    "    corpus_test[i] = lemmatize(corpus_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Английские стоп-слова, от которых надо избавить текст\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление TF-IDF\n",
    "tf_idf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf_train = tf_idf_vectorizer.fit_transform(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = tf_idf_vectorizer.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные поделены на выборки и векторизованы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим ненужные переменные дабы очистить память\n",
    "del comments, corpus_train, corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уменьшим размерность массива для обучения градиентному бустингу\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5,\n",
       "             random_state=42, tol=0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.fit(tf_idf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ядро юпитера не справилось с обрезанием и до 1000 компонент, удалось сократить до 100. При таком сильном усечении массива не стоит надеятся на высокое значение метрики, но посмотрим что получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train_svd = svd.transform(tf_idf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже влоть до пункта 2 идет код работы с BERT для получения эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Возьмем 22000 записей, чтобы ядро осилило\n",
    "train_features_for_emb = train_features.sample(22000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_for_emb = pd.Series(train_target, index=train_features_for_emb.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_for_emb = train_features_for_emb.reset_index(drop=True)\n",
    "train_target_for_emb = train_target_for_emb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = 'bert-base-uncased'\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ограничим длину комментов 512 токенами, так как большее количество в BERT не влезет\n",
    "tokenized = train_features_for_emb.apply(\n",
    "    lambda x: tokenizer.encode(x[:512], add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.AutoConfig.from_pretrained(pretrained_model_name_or_path=pretrained_weights)\n",
    "config.output_hidden_states=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.BertModel.from_pretrained(\n",
    "    'bert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01fffb1c3b84913b8fedab24e43bd02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=44.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 500\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Даже на 22000 записей ядро не выдержало и умерло( и мы остались без эмбеддингов.  \n",
    "Оно меня выбесило, поэтому переходим к обучению логистической регрессии на TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.78 s, sys: 36.5 ms, total: 5.82 s\n",
      "Wall time: 5.82 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12345, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(tf_idf_train, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7553879310344828"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(tf_idf_test)\n",
    "f1_score(test_target, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, ну вот все и готово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучим модель градиентного бустинга из catboost применив кросс-валидацию\n",
    "cv_comment = Pool(data=tf_idf_train,\n",
    "              label=train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_comment_svd = Pool(data=tf_idf_train_svd,\n",
    "              label=train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Параметры модели\n",
    "params = {'iterations': 1000,\n",
    "         'depth': 6,\n",
    "          'loss_function': 'Logloss',\n",
    "         'eval_metric': 'F1',\n",
    "          'learning_rate': 0.1,\n",
    "         'verbose': 20,\n",
    "         'random_state': 12345}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4291132\ttest: 0.4291765\tbest: 0.4291765 (0)\ttotal: 2.15s\tremaining: 35m 52s\n",
      "20:\tlearn: 0.5725016\ttest: 0.5712742\tbest: 0.5712742 (20)\ttotal: 24.8s\tremaining: 19m 17s\n",
      "40:\tlearn: 0.6036546\ttest: 0.5965714\tbest: 0.5965714 (40)\ttotal: 49.4s\tremaining: 19m 14s\n",
      "60:\tlearn: 0.6203272\ttest: 0.6121795\tbest: 0.6121795 (60)\ttotal: 1m 10s\tremaining: 18m 6s\n",
      "80:\tlearn: 0.6325435\ttest: 0.6220651\tbest: 0.6220651 (80)\ttotal: 1m 29s\tremaining: 16m 52s\n",
      "100:\tlearn: 0.6418868\ttest: 0.6286609\tbest: 0.6286609 (100)\ttotal: 1m 48s\tremaining: 16m 4s\n",
      "120:\tlearn: 0.6511747\ttest: 0.6330834\tbest: 0.6330834 (120)\ttotal: 2m 6s\tremaining: 15m 22s\n",
      "140:\tlearn: 0.6602021\ttest: 0.6378591\tbest: 0.6378591 (140)\ttotal: 2m 27s\tremaining: 14m 58s\n",
      "160:\tlearn: 0.6686222\ttest: 0.6412070\tbest: 0.6412070 (160)\ttotal: 2m 46s\tremaining: 14m 27s\n",
      "180:\tlearn: 0.6755148\ttest: 0.6439013\tbest: 0.6441409 (179)\ttotal: 3m 5s\tremaining: 13m 59s\n",
      "200:\tlearn: 0.6818275\ttest: 0.6462451\tbest: 0.6466228 (198)\ttotal: 3m 25s\tremaining: 13m 37s\n",
      "220:\tlearn: 0.6870657\ttest: 0.6481513\tbest: 0.6482587 (219)\ttotal: 3m 45s\tremaining: 13m 14s\n",
      "240:\tlearn: 0.6936192\ttest: 0.6503627\tbest: 0.6505326 (235)\ttotal: 4m 5s\tremaining: 12m 52s\n",
      "260:\tlearn: 0.6997206\ttest: 0.6513412\tbest: 0.6515779 (258)\ttotal: 4m 26s\tremaining: 12m 35s\n",
      "280:\tlearn: 0.7063807\ttest: 0.6524395\tbest: 0.6529186 (273)\ttotal: 4m 45s\tremaining: 12m 10s\n",
      "300:\tlearn: 0.7114386\ttest: 0.6541253\tbest: 0.6544385 (299)\ttotal: 5m 4s\tremaining: 11m 46s\n",
      "320:\tlearn: 0.7169970\ttest: 0.6563211\tbest: 0.6563981 (317)\ttotal: 5m 22s\tremaining: 11m 22s\n",
      "340:\tlearn: 0.7219224\ttest: 0.6564333\tbest: 0.6570122 (329)\ttotal: 5m 41s\tremaining: 11m\n",
      "360:\tlearn: 0.7271506\ttest: 0.6571382\tbest: 0.6572828 (348)\ttotal: 6m\tremaining: 10m 38s\n",
      "380:\tlearn: 0.7320879\ttest: 0.6589531\tbest: 0.6590831 (378)\ttotal: 6m 19s\tremaining: 10m 16s\n",
      "400:\tlearn: 0.7364191\ttest: 0.6597473\tbest: 0.6601551 (396)\ttotal: 6m 40s\tremaining: 9m 57s\n",
      "420:\tlearn: 0.7416484\ttest: 0.6600699\tbest: 0.6602697 (418)\ttotal: 6m 58s\tremaining: 9m 36s\n",
      "440:\tlearn: 0.7464113\ttest: 0.6610788\tbest: 0.6614225 (439)\ttotal: 7m 17s\tremaining: 9m 15s\n",
      "460:\tlearn: 0.7522595\ttest: 0.6622598\tbest: 0.6627655 (457)\ttotal: 7m 36s\tremaining: 8m 53s\n",
      "480:\tlearn: 0.7573979\ttest: 0.6615044\tbest: 0.6627655 (457)\ttotal: 7m 55s\tremaining: 8m 32s\n",
      "500:\tlearn: 0.7621866\ttest: 0.6633159\tbest: 0.6633159 (500)\ttotal: 8m 13s\tremaining: 8m 11s\n",
      "520:\tlearn: 0.7663458\ttest: 0.6638923\tbest: 0.6638983 (519)\ttotal: 8m 32s\tremaining: 7m 51s\n",
      "540:\tlearn: 0.7709662\ttest: 0.6637636\tbest: 0.6640760 (532)\ttotal: 8m 53s\tremaining: 7m 32s\n",
      "560:\tlearn: 0.7754528\ttest: 0.6633567\tbest: 0.6640760 (532)\ttotal: 9m 11s\tremaining: 7m 11s\n",
      "580:\tlearn: 0.7794768\ttest: 0.6638704\tbest: 0.6640760 (532)\ttotal: 9m 31s\tremaining: 6m 51s\n",
      "600:\tlearn: 0.7834312\ttest: 0.6643057\tbest: 0.6647517 (585)\ttotal: 9m 50s\tremaining: 6m 31s\n",
      "620:\tlearn: 0.7879131\ttest: 0.6652382\tbest: 0.6656152 (618)\ttotal: 10m 9s\tremaining: 6m 12s\n",
      "640:\tlearn: 0.7924914\ttest: 0.6656197\tbest: 0.6656552 (639)\ttotal: 10m 28s\tremaining: 5m 51s\n",
      "660:\tlearn: 0.7976468\ttest: 0.6659489\tbest: 0.6668149 (648)\ttotal: 10m 47s\tremaining: 5m 32s\n",
      "680:\tlearn: 0.8017985\ttest: 0.6658208\tbest: 0.6668149 (648)\ttotal: 11m 8s\tremaining: 5m 13s\n",
      "700:\tlearn: 0.8057740\ttest: 0.6658891\tbest: 0.6668149 (648)\ttotal: 11m 35s\tremaining: 4m 56s\n",
      "720:\tlearn: 0.8103974\ttest: 0.6657975\tbest: 0.6668149 (648)\ttotal: 11m 55s\tremaining: 4m 36s\n",
      "740:\tlearn: 0.8137351\ttest: 0.6662746\tbest: 0.6668149 (648)\ttotal: 12m 20s\tremaining: 4m 18s\n",
      "760:\tlearn: 0.8174632\ttest: 0.6653491\tbest: 0.6668149 (648)\ttotal: 12m 39s\tremaining: 3m 58s\n",
      "780:\tlearn: 0.8213729\ttest: 0.6658325\tbest: 0.6668149 (648)\ttotal: 12m 58s\tremaining: 3m 38s\n",
      "800:\tlearn: 0.8260241\ttest: 0.6654900\tbest: 0.6668149 (648)\ttotal: 13m 19s\tremaining: 3m 18s\n",
      "820:\tlearn: 0.8295043\ttest: 0.6656990\tbest: 0.6668149 (648)\ttotal: 13m 38s\tremaining: 2m 58s\n",
      "840:\tlearn: 0.8328473\ttest: 0.6665487\tbest: 0.6670931 (835)\ttotal: 13m 58s\tremaining: 2m 38s\n",
      "860:\tlearn: 0.8364055\ttest: 0.6681109\tbest: 0.6684832 (856)\ttotal: 14m 17s\tremaining: 2m 18s\n",
      "880:\tlearn: 0.8401901\ttest: 0.6688244\tbest: 0.6690281 (877)\ttotal: 14m 36s\tremaining: 1m 58s\n",
      "900:\tlearn: 0.8430348\ttest: 0.6689948\tbest: 0.6690281 (877)\ttotal: 14m 55s\tremaining: 1m 38s\n",
      "920:\tlearn: 0.8472231\ttest: 0.6684744\tbest: 0.6690281 (877)\ttotal: 15m 16s\tremaining: 1m 18s\n",
      "940:\tlearn: 0.8497742\ttest: 0.6687426\tbest: 0.6690281 (877)\ttotal: 15m 35s\tremaining: 58.7s\n",
      "960:\tlearn: 0.8528771\ttest: 0.6687458\tbest: 0.6690281 (877)\ttotal: 15m 55s\tremaining: 38.8s\n",
      "980:\tlearn: 0.8563259\ttest: 0.6689038\tbest: 0.6690281 (877)\ttotal: 16m 14s\tremaining: 18.9s\n",
      "999:\tlearn: 0.8592886\ttest: 0.6691450\tbest: 0.6698231 (991)\ttotal: 16m 33s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-F1-mean</th>\n",
       "      <th>test-F1-std</th>\n",
       "      <th>train-F1-mean</th>\n",
       "      <th>train-F1-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429177</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>0.429113</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.568556</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.568477</td>\n",
       "      <td>0.000609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510174</td>\n",
       "      <td>0.019311</td>\n",
       "      <td>0.509906</td>\n",
       "      <td>0.018087</td>\n",
       "      <td>0.475729</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.475518</td>\n",
       "      <td>0.003752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.521336</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>0.521932</td>\n",
       "      <td>0.013816</td>\n",
       "      <td>0.410308</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.410058</td>\n",
       "      <td>0.003466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.505338</td>\n",
       "      <td>0.027578</td>\n",
       "      <td>0.506219</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.363197</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.362860</td>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.515134</td>\n",
       "      <td>0.016122</td>\n",
       "      <td>0.515028</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.328030</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.327612</td>\n",
       "      <td>0.001883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.858220</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.159546</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.075371</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "      <td>0.669253</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.858655</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.159558</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.075329</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>0.669318</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.859103</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.159561</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.075276</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>0.669014</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.859209</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.159558</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.075216</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>0.669145</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.859289</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.159564</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.075151</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-F1-mean  test-F1-std  train-F1-mean  train-F1-std  \\\n",
       "0             0      0.429177     0.007167       0.429113      0.002662   \n",
       "1             1      0.510174     0.019311       0.509906      0.018087   \n",
       "2             2      0.521336     0.014535       0.521932      0.013816   \n",
       "3             3      0.505338     0.027578       0.506219      0.022688   \n",
       "4             4      0.515134     0.016122       0.515028      0.011787   \n",
       "..          ...           ...          ...            ...           ...   \n",
       "995         995      0.669421     0.003800       0.858220      0.003213   \n",
       "996         996      0.669253     0.003979       0.858655      0.003115   \n",
       "997         997      0.669318     0.003928       0.859103      0.003231   \n",
       "998         998      0.669014     0.003943       0.859209      0.003243   \n",
       "999         999      0.669145     0.004380       0.859289      0.003124   \n",
       "\n",
       "     test-Logloss-mean  test-Logloss-std  train-Logloss-mean  \\\n",
       "0             0.568556          0.000461            0.568477   \n",
       "1             0.475729          0.003272            0.475518   \n",
       "2             0.410308          0.002642            0.410058   \n",
       "3             0.363197          0.000874            0.362860   \n",
       "4             0.328030          0.001361            0.327612   \n",
       "..                 ...               ...                 ...   \n",
       "995           0.159546          0.001758            0.075371   \n",
       "996           0.159558          0.001743            0.075329   \n",
       "997           0.159561          0.001739            0.075276   \n",
       "998           0.159558          0.001738            0.075216   \n",
       "999           0.159564          0.001747            0.075151   \n",
       "\n",
       "     train-Logloss-std  \n",
       "0             0.000609  \n",
       "1             0.003752  \n",
       "2             0.003466  \n",
       "3             0.001314  \n",
       "4             0.001883  \n",
       "..                 ...  \n",
       "995           0.000235  \n",
       "996           0.000246  \n",
       "997           0.000247  \n",
       "998           0.000259  \n",
       "999           0.000266  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(cv_comment, params, fold_count=3, plot=False, as_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {'iterations': 1000,\n",
    "         'depth': 12,\n",
    "          'loss_function': 'Logloss',\n",
    "         'eval_metric': 'F1',\n",
    "          'learning_rate': 0.1,\n",
    "         'verbose': 20,\n",
    "         'random_state': 12345}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5676253\ttest: 0.5589269\tbest: 0.5589269 (0)\ttotal: 12s\tremaining: 3h 19m 49s\n",
      "20:\tlearn: 0.6346613\ttest: 0.5937427\tbest: 0.5937427 (20)\ttotal: 3m 58s\tremaining: 3h 5m 6s\n",
      "40:\tlearn: 0.7061414\ttest: 0.6132653\tbest: 0.6132653 (40)\ttotal: 7m 44s\tremaining: 3h 1m 6s\n",
      "60:\tlearn: 0.7759456\ttest: 0.6235563\tbest: 0.6235563 (60)\ttotal: 11m 30s\tremaining: 2h 57m 7s\n",
      "80:\tlearn: 0.8382217\ttest: 0.6287549\tbest: 0.6287549 (80)\ttotal: 15m 17s\tremaining: 2h 53m 28s\n",
      "100:\tlearn: 0.8882192\ttest: 0.6322109\tbest: 0.6331468 (97)\ttotal: 19m 4s\tremaining: 2h 49m 45s\n",
      "120:\tlearn: 0.9220210\ttest: 0.6357521\tbest: 0.6361134 (112)\ttotal: 22m 48s\tremaining: 2h 45m 39s\n",
      "140:\tlearn: 0.9468698\ttest: 0.6391859\tbest: 0.6394615 (137)\ttotal: 26m 32s\tremaining: 2h 41m 40s\n",
      "160:\tlearn: 0.9661587\ttest: 0.6397797\tbest: 0.6403359 (156)\ttotal: 30m 19s\tremaining: 2h 38m 4s\n",
      "180:\tlearn: 0.9791974\ttest: 0.6421528\tbest: 0.6421528 (180)\ttotal: 34m 3s\tremaining: 2h 34m 4s\n",
      "200:\tlearn: 0.9874288\ttest: 0.6445350\tbest: 0.6445350 (200)\ttotal: 37m 47s\tremaining: 2h 30m 11s\n",
      "220:\tlearn: 0.9930833\ttest: 0.6441065\tbest: 0.6460666 (213)\ttotal: 41m 31s\tremaining: 2h 26m 21s\n",
      "240:\tlearn: 0.9951841\ttest: 0.6458039\tbest: 0.6463039 (239)\ttotal: 45m 15s\tremaining: 2h 22m 31s\n",
      "260:\tlearn: 0.9967388\ttest: 0.6465736\tbest: 0.6466230 (258)\ttotal: 48m 58s\tremaining: 2h 18m 40s\n",
      "280:\tlearn: 0.9976286\ttest: 0.6462154\tbest: 0.6466230 (258)\ttotal: 52m 41s\tremaining: 2h 14m 50s\n",
      "300:\tlearn: 0.9981863\ttest: 0.6463229\tbest: 0.6466230 (258)\ttotal: 56m 25s\tremaining: 2h 11m 3s\n",
      "320:\tlearn: 0.9984548\ttest: 0.6466016\tbest: 0.6468046 (307)\ttotal: 1h 9s\tremaining: 2h 7m 15s\n",
      "340:\tlearn: 0.9986198\ttest: 0.6472721\tbest: 0.6477495 (330)\ttotal: 1h 3m 52s\tremaining: 2h 3m 26s\n",
      "360:\tlearn: 0.9987230\ttest: 0.6480803\tbest: 0.6483902 (359)\ttotal: 1h 7m 36s\tremaining: 1h 59m 40s\n",
      "380:\tlearn: 0.9987641\ttest: 0.6478389\tbest: 0.6487132 (365)\ttotal: 1h 11m 18s\tremaining: 1h 55m 51s\n",
      "400:\tlearn: 0.9987434\ttest: 0.6478228\tbest: 0.6487132 (365)\ttotal: 1h 15m 1s\tremaining: 1h 52m 4s\n",
      "420:\tlearn: 0.9987847\ttest: 0.6479673\tbest: 0.6487132 (365)\ttotal: 1h 18m 44s\tremaining: 1h 48m 17s\n",
      "440:\tlearn: 0.9988261\ttest: 0.6474142\tbest: 0.6487132 (365)\ttotal: 1h 22m 27s\tremaining: 1h 44m 30s\n",
      "460:\tlearn: 0.9988465\ttest: 0.6482292\tbest: 0.6487132 (365)\ttotal: 1h 26m 8s\tremaining: 1h 40m 43s\n",
      "480:\tlearn: 0.9988879\ttest: 0.6491011\tbest: 0.6493547 (475)\ttotal: 1h 29m 51s\tremaining: 1h 36m 57s\n",
      "500:\tlearn: 0.9989085\ttest: 0.6490320\tbest: 0.6497312 (495)\ttotal: 1h 33m 30s\tremaining: 1h 33m 8s\n",
      "520:\tlearn: 0.9989498\ttest: 0.6490622\tbest: 0.6497312 (495)\ttotal: 1h 37m 9s\tremaining: 1h 29m 19s\n",
      "540:\tlearn: 0.9989909\ttest: 0.6487221\tbest: 0.6497312 (495)\ttotal: 1h 40m 51s\tremaining: 1h 25m 34s\n",
      "560:\tlearn: 0.9989910\ttest: 0.6496639\tbest: 0.6501656 (558)\ttotal: 1h 44m 24s\tremaining: 1h 21m 42s\n",
      "580:\tlearn: 0.9989909\ttest: 0.6488513\tbest: 0.6501656 (558)\ttotal: 1h 47m 55s\tremaining: 1h 17m 50s\n",
      "600:\tlearn: 0.9990116\ttest: 0.6494299\tbest: 0.6501656 (558)\ttotal: 1h 51m 27s\tremaining: 1h 13m 59s\n",
      "620:\tlearn: 0.9990115\ttest: 0.6491355\tbest: 0.6501656 (558)\ttotal: 1h 54m 59s\tremaining: 1h 10m 10s\n",
      "640:\tlearn: 0.9990115\ttest: 0.6500053\tbest: 0.6501656 (558)\ttotal: 1h 58m 30s\tremaining: 1h 6m 22s\n",
      "660:\tlearn: 0.9990321\ttest: 0.6504400\tbest: 0.6506148 (659)\ttotal: 2h 1m 55s\tremaining: 1h 2m 31s\n",
      "680:\tlearn: 0.9990321\ttest: 0.6502235\tbest: 0.6511270 (666)\ttotal: 2h 5m 19s\tremaining: 58m 42s\n",
      "700:\tlearn: 0.9990526\ttest: 0.6505802\tbest: 0.6511270 (666)\ttotal: 2h 8m 50s\tremaining: 54m 57s\n",
      "720:\tlearn: 0.9990528\ttest: 0.6508591\tbest: 0.6511270 (666)\ttotal: 2h 12m 22s\tremaining: 51m 13s\n",
      "740:\tlearn: 0.9990528\ttest: 0.6509656\tbest: 0.6516332 (733)\ttotal: 2h 15m 51s\tremaining: 47m 29s\n",
      "760:\tlearn: 0.9990528\ttest: 0.6519131\tbest: 0.6522942 (748)\ttotal: 2h 19m 31s\tremaining: 43m 49s\n",
      "780:\tlearn: 0.9990527\ttest: 0.6519384\tbest: 0.6522942 (748)\ttotal: 2h 23m 12s\tremaining: 40m 9s\n",
      "800:\tlearn: 0.9990529\ttest: 0.6520395\tbest: 0.6522942 (748)\ttotal: 2h 26m 54s\tremaining: 36m 29s\n",
      "820:\tlearn: 0.9990529\ttest: 0.6520368\tbest: 0.6522942 (748)\ttotal: 2h 30m 34s\tremaining: 32m 49s\n",
      "840:\tlearn: 0.9990527\ttest: 0.6520092\tbest: 0.6522942 (748)\ttotal: 2h 34m 12s\tremaining: 29m 9s\n",
      "860:\tlearn: 0.9990527\ttest: 0.6528032\tbest: 0.6528053 (859)\ttotal: 2h 37m 43s\tremaining: 25m 27s\n",
      "880:\tlearn: 0.9990528\ttest: 0.6531187\tbest: 0.6533638 (869)\ttotal: 2h 41m 16s\tremaining: 21m 47s\n",
      "900:\tlearn: 0.9990527\ttest: 0.6528740\tbest: 0.6533638 (869)\ttotal: 2h 44m 51s\tremaining: 18m 6s\n",
      "920:\tlearn: 0.9990528\ttest: 0.6529412\tbest: 0.6534727 (913)\ttotal: 2h 48m 31s\tremaining: 14m 27s\n",
      "940:\tlearn: 0.9990530\ttest: 0.6531154\tbest: 0.6534727 (913)\ttotal: 2h 52m 10s\tremaining: 10m 47s\n",
      "960:\tlearn: 0.9990528\ttest: 0.6532987\tbest: 0.6537479 (951)\ttotal: 2h 55m 49s\tremaining: 7m 8s\n",
      "980:\tlearn: 0.9990529\ttest: 0.6534071\tbest: 0.6537479 (951)\ttotal: 2h 59m 24s\tremaining: 3m 28s\n",
      "999:\tlearn: 0.9990529\ttest: 0.6534644\tbest: 0.6537479 (951)\ttotal: 3h 2m 48s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-F1-mean</th>\n",
       "      <th>test-F1-std</th>\n",
       "      <th>train-F1-mean</th>\n",
       "      <th>train-F1-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558927</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.567625</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.563265</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555481</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.568618</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.471683</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.468980</td>\n",
       "      <td>0.000374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.554462</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.567093</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.404133</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.400545</td>\n",
       "      <td>0.002856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.556846</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.567622</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.352924</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.348472</td>\n",
       "      <td>0.001795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.562850</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.576655</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.312923</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.307629</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>0.653464</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.999053</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.228753</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "      <td>0.653427</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.999053</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.228780</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>0.653535</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>0.999053</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.228803</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>0.653359</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>0.999053</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.228822</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>0.653464</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.999053</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.228844</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-F1-mean  test-F1-std  train-F1-mean  train-F1-std  \\\n",
       "0             0      0.558927     0.004522       0.567625      0.001635   \n",
       "1             1      0.555481     0.008856       0.568618      0.002545   \n",
       "2             2      0.554462     0.006003       0.567093      0.005595   \n",
       "3             3      0.556846     0.006002       0.567622      0.004779   \n",
       "4             4      0.562850     0.005845       0.576655      0.002337   \n",
       "..          ...           ...          ...            ...           ...   \n",
       "995         995      0.653464     0.007376       0.999053      0.000292   \n",
       "996         996      0.653427     0.007351       0.999053      0.000292   \n",
       "997         997      0.653535     0.007320       0.999053      0.000292   \n",
       "998         998      0.653359     0.007372       0.999053      0.000292   \n",
       "999         999      0.653464     0.007376       0.999053      0.000292   \n",
       "\n",
       "     test-Logloss-mean  test-Logloss-std  train-Logloss-mean  \\\n",
       "0             0.564532          0.000147            0.563265   \n",
       "1             0.471683          0.000319            0.468980   \n",
       "2             0.404133          0.002589            0.400545   \n",
       "3             0.352924          0.001583            0.348472   \n",
       "4             0.312923          0.000761            0.307629   \n",
       "..                 ...               ...                 ...   \n",
       "995           0.228753          0.002589            0.002776   \n",
       "996           0.228780          0.002587            0.002775   \n",
       "997           0.228803          0.002585            0.002772   \n",
       "998           0.228822          0.002572            0.002771   \n",
       "999           0.228844          0.002573            0.002768   \n",
       "\n",
       "     train-Logloss-std  \n",
       "0             0.000333  \n",
       "1             0.000374  \n",
       "2             0.002856  \n",
       "3             0.001795  \n",
       "4             0.001132  \n",
       "..                 ...  \n",
       "995           0.000026  \n",
       "996           0.000027  \n",
       "997           0.000029  \n",
       "998           0.000030  \n",
       "999           0.000033  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(cv_comment, params2, fold_count=3, plot=False, as_pandas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший показатель f1 при depth = 6 и iterations = 991."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель CatBoostClassifier сначало на полном массиве TF-IDF, затем на усеченном\n",
    "model_catboost = CatBoostClassifier(iterations=991,\n",
    "         depth=6,\n",
    "         eval_metric='F1',\n",
    "         learning_rate=0.1,\n",
    "         verbose=20,\n",
    "         random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4125807\ttotal: 6.4s\tremaining: 1h 45m 33s\n",
      "20:\tlearn: 0.5161600\ttotal: 1m 54s\tremaining: 1h 27m 53s\n",
      "40:\tlearn: 0.5790973\ttotal: 3m 43s\tremaining: 1h 26m 8s\n",
      "60:\tlearn: 0.6070712\ttotal: 5m 31s\tremaining: 1h 24m 20s\n",
      "80:\tlearn: 0.6281897\ttotal: 7m 22s\tremaining: 1h 22m 53s\n",
      "100:\tlearn: 0.6449178\ttotal: 9m 13s\tremaining: 1h 21m 15s\n",
      "120:\tlearn: 0.6607485\ttotal: 11m 4s\tremaining: 1h 19m 39s\n",
      "140:\tlearn: 0.6731599\ttotal: 12m 53s\tremaining: 1h 17m 43s\n",
      "160:\tlearn: 0.6837821\ttotal: 14m 44s\tremaining: 1h 15m 57s\n",
      "180:\tlearn: 0.6918656\ttotal: 16m 34s\tremaining: 1h 14m 10s\n",
      "200:\tlearn: 0.7025417\ttotal: 18m 24s\tremaining: 1h 12m 19s\n",
      "220:\tlearn: 0.7126799\ttotal: 20m 13s\tremaining: 1h 10m 27s\n",
      "240:\tlearn: 0.7196243\ttotal: 22m 3s\tremaining: 1h 8m 37s\n",
      "260:\tlearn: 0.7236888\ttotal: 23m 52s\tremaining: 1h 6m 47s\n",
      "280:\tlearn: 0.7295377\ttotal: 25m 44s\tremaining: 1h 5m 1s\n",
      "300:\tlearn: 0.7339285\ttotal: 27m 35s\tremaining: 1h 3m 14s\n",
      "320:\tlearn: 0.7374702\ttotal: 29m 27s\tremaining: 1h 1m 28s\n",
      "340:\tlearn: 0.7416844\ttotal: 31m 17s\tremaining: 59m 39s\n",
      "360:\tlearn: 0.7454429\ttotal: 33m 8s\tremaining: 57m 50s\n",
      "380:\tlearn: 0.7492370\ttotal: 34m 58s\tremaining: 56m\n",
      "400:\tlearn: 0.7539005\ttotal: 36m 49s\tremaining: 54m 10s\n",
      "420:\tlearn: 0.7566933\ttotal: 38m 40s\tremaining: 52m 21s\n",
      "440:\tlearn: 0.7592846\ttotal: 40m 30s\tremaining: 50m 30s\n",
      "460:\tlearn: 0.7611707\ttotal: 42m 20s\tremaining: 48m 40s\n",
      "480:\tlearn: 0.7641794\ttotal: 44m 11s\tremaining: 46m 51s\n",
      "500:\tlearn: 0.7644626\ttotal: 46m 1s\tremaining: 45m 1s\n",
      "520:\tlearn: 0.7668479\ttotal: 47m 51s\tremaining: 43m 10s\n",
      "540:\tlearn: 0.7687982\ttotal: 49m 42s\tremaining: 41m 20s\n",
      "560:\tlearn: 0.7702735\ttotal: 51m 33s\tremaining: 39m 31s\n",
      "580:\tlearn: 0.7720130\ttotal: 53m 24s\tremaining: 37m 41s\n",
      "600:\tlearn: 0.7739941\ttotal: 55m 14s\tremaining: 35m 51s\n",
      "620:\tlearn: 0.7748878\ttotal: 57m 7s\tremaining: 34m 1s\n",
      "640:\tlearn: 0.7758920\ttotal: 58m 58s\tremaining: 32m 11s\n",
      "660:\tlearn: 0.7769105\ttotal: 1h 48s\tremaining: 30m 21s\n",
      "680:\tlearn: 0.7789271\ttotal: 1h 2m 38s\tremaining: 28m 30s\n",
      "700:\tlearn: 0.7821578\ttotal: 1h 4m 29s\tremaining: 26m 40s\n",
      "720:\tlearn: 0.7845601\ttotal: 1h 6m 21s\tremaining: 24m 50s\n",
      "740:\tlearn: 0.7852967\ttotal: 1h 8m 11s\tremaining: 23m\n",
      "760:\tlearn: 0.7867503\ttotal: 1h 10m 3s\tremaining: 21m 10s\n",
      "780:\tlearn: 0.7880671\ttotal: 1h 11m 55s\tremaining: 19m 20s\n",
      "800:\tlearn: 0.7889908\ttotal: 1h 13m 47s\tremaining: 17m 30s\n",
      "820:\tlearn: 0.7910348\ttotal: 1h 15m 39s\tremaining: 15m 39s\n",
      "840:\tlearn: 0.7938880\ttotal: 1h 17m 30s\tremaining: 13m 49s\n",
      "860:\tlearn: 0.7965812\ttotal: 1h 19m 23s\tremaining: 11m 59s\n",
      "880:\tlearn: 0.7983500\ttotal: 1h 21m 14s\tremaining: 10m 8s\n",
      "900:\tlearn: 0.7997347\ttotal: 1h 23m 5s\tremaining: 8m 18s\n",
      "920:\tlearn: 0.8018542\ttotal: 1h 24m 58s\tremaining: 6m 27s\n",
      "940:\tlearn: 0.8031764\ttotal: 1h 26m 50s\tremaining: 4m 36s\n",
      "960:\tlearn: 0.8040049\ttotal: 1h 28m 42s\tremaining: 2m 46s\n",
      "980:\tlearn: 0.8049840\ttotal: 1h 30m 31s\tremaining: 55.4s\n",
      "990:\tlearn: 0.8055490\ttotal: 1h 31m 28s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f8af6c35d50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_catboost.fit(cv_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test_svd = svd.transform(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_test = Pool(data=tf_idf_test, label=test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7569942873883113"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model_catboost.predict(pool_test)\n",
    "f1_score(test_target, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура! Ноутбук справился с полным массивом и ядро не умерло. Хвала тем, кто ее заслуживает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catboost_svd = CatBoostClassifier(iterations=991,\n",
    "         depth=6,\n",
    "         eval_metric='F1',\n",
    "         learning_rate=0.1,\n",
    "         verbose=20,\n",
    "         random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4329339\ttotal: 481ms\tremaining: 7m 56s\n",
      "20:\tlearn: 0.5802242\ttotal: 9.67s\tremaining: 7m 26s\n",
      "40:\tlearn: 0.6062653\ttotal: 18.9s\tremaining: 7m 17s\n",
      "60:\tlearn: 0.6214009\ttotal: 27.5s\tremaining: 6m 59s\n",
      "80:\tlearn: 0.6306661\ttotal: 36.4s\tremaining: 6m 49s\n",
      "100:\tlearn: 0.6404144\ttotal: 45.3s\tremaining: 6m 39s\n",
      "120:\tlearn: 0.6486345\ttotal: 55.1s\tremaining: 6m 35s\n",
      "140:\tlearn: 0.6562223\ttotal: 1m 3s\tremaining: 6m 25s\n",
      "160:\tlearn: 0.6625410\ttotal: 1m 12s\tremaining: 6m 14s\n",
      "180:\tlearn: 0.6688776\ttotal: 1m 21s\tremaining: 6m 4s\n",
      "200:\tlearn: 0.6745134\ttotal: 1m 30s\tremaining: 5m 54s\n",
      "220:\tlearn: 0.6802203\ttotal: 1m 38s\tremaining: 5m 44s\n",
      "240:\tlearn: 0.6855705\ttotal: 1m 47s\tremaining: 5m 35s\n",
      "260:\tlearn: 0.6910078\ttotal: 1m 56s\tremaining: 5m 27s\n",
      "280:\tlearn: 0.6951238\ttotal: 2m 5s\tremaining: 5m 17s\n",
      "300:\tlearn: 0.6986002\ttotal: 2m 14s\tremaining: 5m 8s\n",
      "320:\tlearn: 0.7030211\ttotal: 2m 23s\tremaining: 4m 59s\n",
      "340:\tlearn: 0.7089926\ttotal: 2m 32s\tremaining: 4m 49s\n",
      "360:\tlearn: 0.7110842\ttotal: 2m 40s\tremaining: 4m 40s\n",
      "380:\tlearn: 0.7151631\ttotal: 2m 49s\tremaining: 4m 31s\n",
      "400:\tlearn: 0.7188709\ttotal: 2m 58s\tremaining: 4m 22s\n",
      "420:\tlearn: 0.7225813\ttotal: 3m 7s\tremaining: 4m 13s\n",
      "440:\tlearn: 0.7258734\ttotal: 3m 16s\tremaining: 4m 5s\n",
      "460:\tlearn: 0.7300274\ttotal: 3m 26s\tremaining: 3m 57s\n",
      "480:\tlearn: 0.7336848\ttotal: 3m 35s\tremaining: 3m 48s\n",
      "500:\tlearn: 0.7363979\ttotal: 3m 43s\tremaining: 3m 38s\n",
      "520:\tlearn: 0.7399227\ttotal: 3m 52s\tremaining: 3m 29s\n",
      "540:\tlearn: 0.7453208\ttotal: 4m\tremaining: 3m 20s\n",
      "560:\tlearn: 0.7478064\ttotal: 4m 8s\tremaining: 3m 10s\n",
      "580:\tlearn: 0.7515247\ttotal: 4m 16s\tremaining: 3m 1s\n",
      "600:\tlearn: 0.7547874\ttotal: 4m 24s\tremaining: 2m 51s\n",
      "620:\tlearn: 0.7575490\ttotal: 4m 32s\tremaining: 2m 42s\n",
      "640:\tlearn: 0.7607440\ttotal: 4m 41s\tremaining: 2m 33s\n",
      "660:\tlearn: 0.7626771\ttotal: 4m 50s\tremaining: 2m 24s\n",
      "680:\tlearn: 0.7663369\ttotal: 4m 58s\tremaining: 2m 16s\n",
      "700:\tlearn: 0.7696498\ttotal: 5m 7s\tremaining: 2m 7s\n",
      "720:\tlearn: 0.7718088\ttotal: 5m 14s\tremaining: 1m 57s\n",
      "740:\tlearn: 0.7749092\ttotal: 5m 23s\tremaining: 1m 48s\n",
      "760:\tlearn: 0.7778047\ttotal: 5m 30s\tremaining: 1m 40s\n",
      "780:\tlearn: 0.7803465\ttotal: 5m 38s\tremaining: 1m 31s\n",
      "800:\tlearn: 0.7832916\ttotal: 5m 47s\tremaining: 1m 22s\n",
      "820:\tlearn: 0.7866378\ttotal: 5m 57s\tremaining: 1m 13s\n",
      "840:\tlearn: 0.7893853\ttotal: 6m 5s\tremaining: 1m 5s\n",
      "860:\tlearn: 0.7930704\ttotal: 6m 13s\tremaining: 56.4s\n",
      "880:\tlearn: 0.7959496\ttotal: 6m 21s\tremaining: 47.6s\n",
      "900:\tlearn: 0.7979774\ttotal: 6m 29s\tremaining: 38.9s\n",
      "920:\tlearn: 0.8022454\ttotal: 6m 37s\tremaining: 30.2s\n",
      "940:\tlearn: 0.8035740\ttotal: 6m 45s\tremaining: 21.5s\n",
      "960:\tlearn: 0.8065434\ttotal: 6m 53s\tremaining: 12.9s\n",
      "980:\tlearn: 0.8095982\ttotal: 7m 1s\tremaining: 4.3s\n",
      "990:\tlearn: 0.8109514\ttotal: 7m 5s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f8af6b02150>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_catboost_svd.fit(cv_comment_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_test_svd = Pool(data=tf_idf_test_svd, label=test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6813153042409343"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_svd = model_catboost_svd.predict(pool_test_svd)\n",
    "f1_score(test_target, predict_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и следовало ожидать при сильном обрезании матрицы модель проигрывает в качестве и полученное значение метрики F1 нас не удовлетворяет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо себя показала логистическая регрессия при обучении на *TF-IDF*, полученная метрика *F1* = 0.755. Еще большее значение метрики удалось получить при обучение модели *CatBoostClassifier* на той же выборке: *F1* = 0.757. Однако, я бы остановился на модели логистической регрессии, так как время обучения этой модели по сравнению с *CatBoostClassifier* (~ 6c против 1ч30мин у CatBoost) перекрывает незначительную разницу в значениях метрики *F1* для этих моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
